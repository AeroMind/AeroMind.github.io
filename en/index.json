[{"content":" 关于 AeroMind # 这里是 AeroMind 的技术博客，专注于：\nAI Agent 的设计与实践 Context Engineering 的深度思考 工程实践的经验分享 文笔简洁，内容深刻，不哗众取宠。\n","date":"December 9, 2025","externalUrl":null,"permalink":"/about/","section":"关于","summary":"\u003ch2 class=\"relative group\"\u003e关于 AeroMind\n    \u003cdiv id=\"关于-aeromind\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#%e5%85%b3%e4%ba%8e-aeromind\" aria-label=\"\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003e这里是 AeroMind 的技术博客，专注于：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAI Agent 的设计与实践\u003c/li\u003e\n\u003cli\u003eContext Engineering 的深度思考\u003c/li\u003e\n\u003cli\u003e工程实践的经验分享\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e文笔简洁，内容深刻，不哗众取宠。\u003c/strong\u003e\u003c/p\u003e","title":"关于","type":"about"},{"content":"","date":"6 December 2025","externalUrl":null,"permalink":"/en/","section":"AeroMind","summary":"","title":"AeroMind","type":"page"},{"content":"","date":"6 December 2025","externalUrl":null,"permalink":"/en/tags/agent/","section":"Tags","summary":"","title":"Agent","type":"tags"},{"content":"","date":"6 December 2025","externalUrl":null,"permalink":"/en/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":"","date":"6 December 2025","externalUrl":null,"permalink":"/en/tags/claude/","section":"Tags","summary":"","title":"Claude","type":"tags"},{"content":"","date":"6 December 2025","externalUrl":null,"permalink":"/en/tags/context/","section":"Tags","summary":"","title":"Context","type":"tags"},{"content":" 0. Introduction # How does an Agent \u0026ldquo;see\u0026rdquo; the world?\nIt has no eyes, no ears—just an input window. No matter how complex the outside world is, an Agent can only perceive one thing: Context.\nA prompt is context. A tool call\u0026rsquo;s return value is context. A file\u0026rsquo;s contents are context. An error message is context.\nFor an Agent: Everything is context.\nThis article traces how context evolved from static text into the sole interface through which Agents perceive the world. This evolution is the birth story of Context Engineering.\n1. The Origin of Context — In-Context Learning # The traditional machine learning paradigm was simple: one task, one model.\nSentiment analysis required one model; machine translation required another. Capabilities were baked into parameters—switching tasks meant retraining.\nLLMs broke this paradigm. The GPT series proved something remarkable: a sufficiently large language model can switch tasks through context alone. No retraining needed—just change the prompt.\nTraditional models: Task → Training → Specialized model\nLLMs: General model + Context → Any task\nWhat does this resemble? The shift from specialized hardware to general-purpose computers.\nEarly computing was specialized—one machine did one thing. General-purpose computers changed everything: the same machine, with a different program, could do different things.\nA program is a computer\u0026rsquo;s Context.\nEven more remarkable is few-shot learning. Give the model a few examples, and it learns a new task:\nInput: happy → positive Input: sad → negative Input: joyful → ? The model outputs positive.\nNo training, no fine-tuning—the examples themselves are the learning. Traditional machine learning required collecting data, engineering features, and training models. LLMs just need a few examples in the context.\nThis is In-Context Learning: capabilities no longer reside solely in parameters. Context becomes the carrier of capability.\nThis is the starting point of Context Engineering—we discovered that Context can carry capability, just as programs can carry computational logic.\n2. Manually Crafting Context — Prompt Engineering # If Context can carry capability, how do we design better Context?\nEnter Prompt Engineering.\nThe simplest approach is role assignment:\nYou are a senior code review expert\u0026hellip;\nThen comes structured instructions:\n## Task Review the following code ## Requirements 1. Check for security vulnerabilities 2. Check for performance issues 3. Provide improvement suggestions ## Code ...\nMore advanced is Chain-of-Thought:\nLet\u0026rsquo;s think step by step\u0026hellip;\nAnd ReAct, which alternates between reasoning and action:\nThought: I need to first look at the file structure Action: list_files Observation: \u0026hellip; Thought: Now I need to\u0026hellip;\nIf we think of an LLM as a program, the Prompt is like its configuration file—defining behavior patterns, input formats, and output specifications. Good configuration makes program behavior predictable and controllable.\nWhat is the essence of Prompt Engineering? Manually crafting every token to maximize the value of a limited context window.\nBut the limitations are obvious: manual, static, and unscalable.\nWhen your knowledge base has a million documents, you can\u0026rsquo;t manually stuff relevant content into a prompt.\n3. Automatic Context Retrieval — RAG # Limited context window, unlimited external knowledge. What do we do?\nRAG (Retrieval-Augmented Generation) provides the answer: let relevant information come to you. User asks → Retrieve relevant documents → Inject into Context → Generate response. No need to cram all knowledge into the prompt—just retrieve the most relevant parts when needed.\nWhat does this resemble? A program reading data from a file system instead of hardcoding everything.\nThe Scarcity of Context # Here we introduce a key concept: Context Rot.\nAs the number of tokens in the context window increases, the model\u0026rsquo;s ability to accurately recall information degrades. The Transformer architecture requires each token to attend to all other tokens, creating n² relationships. As n grows, attention gets diluted.\nThis means: Context is a scarce resource with diminishing marginal returns. More isn\u0026rsquo;t always better—you need to find the smallest possible set of high-signal tokens.\nRAG\u0026rsquo;s Limitations # RAG is essentially a fixed-pattern search tool: fixed trigger, fixed process, fixed capability.\nIts breakthrough: moving from \u0026ldquo;manually stuffing Context\u0026rdquo; to \u0026ldquo;automatically fetching Context.\u0026rdquo; But its limitation is also \u0026ldquo;fixed\u0026rdquo;—what if the Agent needs to execute code or call an API instead of retrieving documents?\n4. Dynamically Generating Context — Tools # RAG is a special case of tools. Tools are the generalization of RAG.\nRAG: Fixed trigger → Retrieval → Return text Tools: Agent decides → Any tool → Return result\nLet\u0026rsquo;s clarify a concept here: Workflows are systems where LLMs and tools are orchestrated through predefined code paths. Agents are systems where LLMs dynamically direct their own processes and tool usage. The key difference is who makes the decisions.\nTools make Agents possible: not just retrieval but execution, not just fixed triggers but Agent-driven decisions, not just one tool but a toolkit. This resembles executable programs in Unix—cat reads files, grep searches, sh executes commands. Simple, focused, composable.\nTool outputs are injected into Context, becoming the Agent\u0026rsquo;s new perception. This creates a loop: actions produce new Context, new Context drives the next action. For the first time, Agents can \u0026ldquo;do things\u0026rdquo; and \u0026ldquo;see results.\u0026rdquo;\nMCP: Standardizing Tools # As Agents need to connect to more external systems, each system requires separate integration code. MCP (Model Context Protocol) solves this—it\u0026rsquo;s USB-C for LLMs.\nThink of MCP as a universal connector. Just as USB-C provides a universal connector for your phone, laptop, and other devices, MCP provides a universal format for LLMs to connect with external systems. MCP provides a unified protocol, letting Agents connect to all MCP-supporting services the same way.\nMCP\u0026rsquo;s significance goes beyond reducing duplicate work. It makes Tools a discoverable, composable ecosystem. Agents don\u0026rsquo;t need to know all tools in advance—they can discover and use new tools at runtime.\n5. Encapsulating Context Patterns — Skills # With tools, Agents can do many things. But problems emerge:\nToo many tools, not enough Context. Each tool\u0026rsquo;s definition, parameters, and return values consume tokens. When an Agent connects to dozens or hundreds of tools, tool definitions alone can eat up significant context window space.\nAnd atomic tools are too low-level. Reading files, writing files, executing commands—these are raw materials for capability, not capability itself.\n\u0026ldquo;Code review\u0026rdquo; is a capability. It requires:\nReading code files Understanding project structure Checking against specific standards Outputting structured review comments How do we combine these into a reusable capability?\nSkill: Discoverable, Loadable Context Packages # The essence of a Skill is: an organized folder of instructions, scripts, and resources that Agents can discover and load dynamically to perform better at specific tasks.\nThis definition has three key points:\nFolder structure: Not just a prompt, but an organized collection of resources Discoverable: The Agent knows which Skills are available On-demand loading: Only loaded into Context when relevant The core design principle of Skills is Progressive Disclosure:\nWhy this design? Because Context is a scarce resource.\nIf all Skills\u0026rsquo; complete contents were stuffed into Context, it would trigger Context Rot. Progressive disclosure lets Agents load only needed information, maintaining high signal-to-noise ratio in Context.\nSkill vs Shell Scripts # Unix philosophy shines here again: compose small programs with pipes to accomplish complex tasks.\ncat access.log | grep \u0026#34;ERROR\u0026#34; | sort | uniq -c | sort -rn | head -10 This command combines 6 small programs to accomplish \u0026ldquo;find the 10 most common errors.\u0026rdquo;\nSkills and Shell scripts share similarities:\nTool → Single command (cat, grep, sort) Skill → Shell script (workflow combining multiple commands) But Skills are more flexible than Shell scripts:\nShell scripts are fixed processes Skills are guidance + resources—Agents can apply them flexibly Skills can also include executable code. Large language models excel at many tasks, but certain operations are better suited for traditional code execution. For example, sorting a list via token generation is far more expensive than simply running a sorting algorithm. Beyond efficiency concerns, many applications require the deterministic reliability that only code can provide.\nFrom a Context Engineering perspective, Skills are reusable Context patterns—predefined specifications for what information should enter Context, in what order, and how it should be processed.\n6. Managing Context — The Challenge of Long-Running Tasks # Previous chapters covered Context sources: where to get information.\nBut there\u0026rsquo;s another dimension: Context management. When tasks span tens of minutes or even hours, generating tokens far exceeding the context window, what do we do?\nCompaction: Compressing History # The most direct approach is compaction.\nCompaction is the practice of taking a conversation nearing the context window limit, summarizing its contents, and reinitiating a new context window with the summary.\nThe art of compaction lies in choosing what to keep. Overly aggressive compaction can result in the loss of subtle but critical context; too conservative fails to achieve the goal.\nA low-risk compaction strategy is clearing tool call results. Once a tool has been called deep in the message history, why would the agent need to see the raw result again?\nStructured Note-taking: Agentic Memory # A more elegant approach is letting the Agent take its own notes.\nStructured note-taking, or agentic memory, is a technique where the agent regularly writes notes persisted to memory outside of the context window. These notes get pulled back into the context window at later times.\nThis is like humans taking notes: we don\u0026rsquo;t remember every detail, but we record key points and consult them when needed.\nAn interesting example is Claude playing Pokémon. The agent maintains precise tallies across thousands of game steps—tracking objectives, remembering which key achievements it has unlocked, and maintaining strategic notes of combat strategies that help it learn which attacks work best against different opponents. After context resets, the agent reads its own notes and continues multi-hour training sequences or dungeon explorations.\nSub-agent Architectures: Divide and Conquer # The third approach is sub-agent architectures.\nRather than one agent attempting to maintain state across an entire project, specialized sub-agents can handle focused tasks with clean context windows. The main agent coordinates with a high-level plan while sub-agents perform deep technical work. Each sub-agent might explore extensively, but returns only a condensed, distilled summary of its work.\nA sub-agent might consume tens of thousands of tokens exploring, but returns only 1,000-2,000 tokens of distilled results. This achieves separation of concerns—detailed search context is isolated within sub-agents, while the main agent focuses on synthesizing and analyzing the results.\nWhich Approach to Choose? # Compaction: Maintains conversational flow for tasks requiring extensive back-and-forth Note-taking: Excels for iterative development with clear milestones Sub-agent architectures: Handle complex research and analysis where parallel exploration pays dividends These three approaches can be combined.\nIsolated Environments: External Memory Across Sessions # When tasks span hours or even days, each new context window is a blank slate. Imagine shift engineers handing off, but each one loses memory of the previous shift—this is the challenge of long-running Agents.\nThe solution is isolated runtime environments: file systems persist code and documentation, Git records changes that can be rolled back, progress files record work logs. Each session ends by leaving the environment in a \u0026ldquo;clean state.\u0026rdquo; The next session reads progress files and git log, resuming work within seconds. Isolated environments are the Agent\u0026rsquo;s \u0026ldquo;external memory,\u0026rdquo; compensating for the context window\u0026rsquo;s limitations.\nThe key insight: Even as model capabilities improve, Context management remains a core challenge in scenarios demanding peak performance.\n7. The Complete Source of Context — Environment # Now let\u0026rsquo;s step back and see the full picture.\nIn each previous chapter, we used operating system analogies:\nContext is like program input Prompt is like configuration files RAG is like file system reads Tools are like executable programs Skills are like applications This isn\u0026rsquo;t coincidence. We\u0026rsquo;re building an operating system for Agents.\nEnvironment → Operating system (complete runtime environment) Agent → User/Shell (decision-making entity) Tools → Command-line programs (atomic capabilities) Skills → Applications (packaged capability combinations) Context → stdin/stdout (unified information interface) This evokes Unix design philosophy: Everything is a file. In Unix, hardware, processes, and network connections are all abstracted as files. Programs interact with the world through a unified file interface.\nUnix design philosophy maps perfectly here:\nEverything is a file → Everything is context Small programs do one thing → Tools do one thing Compose programs with pipes → Compose Tools with Skills Text as universal interface → Context as universal interface Shell as glue → Agent as glue Key insight: Agents don\u0026rsquo;t directly touch the Environment—everything is perceived through Context.\nJust as Unix programs read input through stdin and output results through stdout, Agents perceive the world and express intent through Context.\nWhy Coding Agents? # Here we address a more fundamental question: Why do we emphasize Coding Agents so much?\nBecause we believe: Agents are a viable path to AGI. And Coding Agents are the most critical form on this path.\nThe reason is simple: Any open-ended task can be transformed into computer operations. And code execution is the bridge connecting everything.\nThink about it:\nWrite a report → Operate file system + call writing tools Analyze data → Execute Python scripts + generate visualizations Deploy services → Execute command line + configure environments Design products → Call design tool APIs + generate prototypes Code is the universal glue. An Agent that can write code can theoretically complete any task that can be done with a computer.\nIn other words: Any task currently done by humans operating computers could potentially be done autonomously by Agents in the future.\nThe Unique Value of Code Execution # Code execution isn\u0026rsquo;t just about \u0026ldquo;doing things\u0026rdquo;—it also solves core Context Engineering challenges:\n1. Filter data, reduce tokens\n# Without code execution: 10,000 rows all enter Context tool_call: get_spreadsheet(id=\u0026#34;abc123\u0026#34;) → Returns 10,000 rows, all enter Context # With code execution: filter in execution environment data = get_spreadsheet(id=\u0026#34;abc123\u0026#34;) pending = [row for row in data if row[\u0026#34;status\u0026#34;] == \u0026#34;pending\u0026#34;] print(f\u0026#34;Found {len(pending)} pending orders\u0026#34;) print(pending[:5]) # Only 5 rows return to Context 2. Protect privacy\nIntermediate data can stay in the execution environment without entering the model\u0026rsquo;s Context. Sensitive information (emails, phone numbers) can be automatically anonymized.\n3. Persist state\nAgents can write intermediate results to files, continuing work across context resets. They can even save successful code as reusable functions—this is the embryo of Skills.\nThis is why code execution capability is central to the Environment:\nFor Coding Agents:\nCode file contents → Context Terminal execution results → Context Test pass/fail → Context Compilation errors → Context LSP type hints → Context Environment is the ultimate source of Context. Context is the Agent\u0026rsquo;s only interface with the world. Code execution is the Agent\u0026rsquo;s primary way of changing the world.\n8. Conclusion: The Full Picture of Context Engineering # Looking back at this journey:\nEach step answers the same question: How do we give Agents better Context?\nPrompt Engineering: Manually polish every token RAG: Automatically retrieve relevant information Tools: Dynamically execute to obtain new information Skills: Encapsulate reusable Context patterns Environment: Provide complete information sources And Context management (Compaction, Structured Note-taking, Sub-agent Architectures) answers another question: How do we maximize Context value within a limited window?\nContext Engineering = Sources × Management\nAll of this points to a bigger picture:\nWe\u0026rsquo;re building an operating system for Agents.\nUnix proved the vitality of a design philosophy over 50 years:\nEverything is a file Small programs do one thing well Compose programs with pipes Text as universal interface The Agent world is recreating this philosophy:\nEverything is context Tools do one thing well Compose Tools with Skills Context as universal interface Finally, returning to the opening question:\nHow does an Agent \u0026ldquo;see\u0026rdquo; the world?\nThe answer is always: Context.\nAn Agent\u0026rsquo;s capability ceiling = Context\u0026rsquo;s quality ceiling\nThis is Context Engineering.\nReferences # [1] Building Effective AI Agents: https://www.anthropic.com/engineering/building-effective-agents\n[2] Effective Context Engineering for AI Agents: https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents\n[3] What is Model Context Protocol (MCP)?: https://www.claude.com/blog/what-is-model-context-protocol\n[4] Code Execution with MCP: Building More Efficient Agents: https://www.anthropic.com/engineering/code-execution-with-mcp\n[5] Introducing Agent Skills: https://www.claude.com/blog/skills\n[6] Equipping Agents for the Real World with Agent Skills: https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills\n[7] Effective Harnesses for Long-Running Agents: https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents\nThis article was co-created with Claude Opus 4.5 ✨\n","date":"6 December 2025","externalUrl":null,"permalink":"/en/posts/context-journey-blog/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e0. Introduction\n    \u003cdiv id=\"0-introduction\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#0-introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003eHow does an Agent \u0026ldquo;see\u0026rdquo; the world?\u003c/p\u003e\n\u003cp\u003eIt has no eyes, no ears—just an input window. No matter how complex the outside world is, an Agent can only perceive one thing: \u003cstrong\u003eContext\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eA prompt is context. A tool call\u0026rsquo;s return value is context. A file\u0026rsquo;s contents are context. An error message is context.\u003c/p\u003e\n\u003cp\u003eFor an Agent: \u003cstrong\u003eEverything is context\u003c/strong\u003e.\u003c/p\u003e","title":"From Prompt to Environment: The Evolution of Context — Understanding the Core Progression of Agent Applications","type":"posts"},{"content":"","date":"6 December 2025","externalUrl":null,"permalink":"/en/tags/llm/","section":"Tags","summary":"","title":"LLM","type":"tags"},{"content":"","date":"6 December 2025","externalUrl":null,"permalink":"/en/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"6 December 2025","externalUrl":null,"permalink":"/en/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","externalUrl":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]