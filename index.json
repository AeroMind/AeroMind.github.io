[{"content":"","date":"2025年12月9日","externalUrl":null,"permalink":"/","section":"AeroMind","summary":"","title":"AeroMind","type":"page"},{"content":" 关于 AeroMind # 这里是 AeroMind 的技术博客，专注于：\nAI Agent 的设计与实践 Context Engineering 的深度思考 工程实践的经验分享 文笔简洁，内容深刻，不哗众取宠。\n","date":"2025年12月9日","externalUrl":null,"permalink":"/about/","section":"关于","summary":"\u003ch2 class=\"relative group\"\u003e关于 AeroMind\n    \u003cdiv id=\"关于-aeromind\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#%e5%85%b3%e4%ba%8e-aeromind\" aria-label=\"\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003e这里是 AeroMind 的技术博客，专注于：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAI Agent 的设计与实践\u003c/li\u003e\n\u003cli\u003eContext Engineering 的深度思考\u003c/li\u003e\n\u003cli\u003e工程实践的经验分享\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e文笔简洁，内容深刻，不哗众取宠。\u003c/strong\u003e\u003c/p\u003e","title":"关于","type":"about"},{"content":"","date":"2025年12月6日","externalUrl":null,"permalink":"/tags/agent/","section":"Tags","summary":"","title":"Agent","type":"tags"},{"content":"","date":"2025年12月6日","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":"","date":"2025年12月6日","externalUrl":null,"permalink":"/tags/claude/","section":"Tags","summary":"","title":"Claude","type":"tags"},{"content":"","date":"2025年12月6日","externalUrl":null,"permalink":"/tags/context/","section":"Tags","summary":"","title":"Context","type":"tags"},{"content":"","date":"2025年12月6日","externalUrl":null,"permalink":"/tags/llm/","section":"Tags","summary":"","title":"LLM","type":"tags"},{"content":"","date":"2025年12月6日","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2025年12月6日","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" 0. 引子 # Agent 如何\u0026quot;看见\u0026quot;世界？\n它没有眼睛，没有耳朵，只有一个输入窗口。无论外面的世界多复杂，Agent 能感知的只有一样东西：Context。\n一段 prompt 是 context，一次工具调用的返回是 context，一个文件的内容是 context，一条报错信息也是 context。\n对于 Agent 来说：Everything is context。\n这篇文章讲述 context 如何从一段静态文字，演进为 Agent 感知世界的唯一接口。这个演进过程，就是 Context Engineering 的诞生之路。\n1. Context 的起源 — In-Context Learning # 传统机器学习的范式很简单：一个任务，训练一个模型。\n情感分析是一个模型，机器翻译是另一个模型。能力固化在参数里，换任务就要重新训练。\nLLM 打破了这个范式。GPT 系列证明了一件事：一个足够大的语言模型，可以通过 context 来切换任务。你不需要重新训练，只需要换一段 prompt。\n传统模型：任务 → 训练 → 专用模型\nLLM：通用模型 + Context → 任意任务\n这像什么？像是从专用硬件到通用计算机的转变。\n早期计算是专用的——一台机器做一件事。通用计算机的出现改变了这一切：同一台机器，换一个程序，就能做不同的事。\n程序是计算机的 Context。\n更神奇的是 few-shot learning。给模型几个示例，它就能学会新任务：\n输入：高兴 → positive 输入：难过 → negative 输入：开心 → ? 模型会输出 positive。\n没有训练，没有微调，示例本身就是学习。传统机器学习需要收集数据、设计特征、训练模型——而 LLM 只需要几个例子放进 context。\n这就是 In-Context Learning：能力不再只存在于参数中，Context 成为能力的载体。\n这是 Context Engineering 的起点——我们发现，Context 可以承载能力，就像程序可以承载计算逻辑。\n2. 手动构建 Context — Prompt Engineering # 既然 Context 能承载能力，那如何设计更好的 Context？\nPrompt Engineering 应运而生。\n最简单的是角色设定：\n你是一个资深的代码审查专家\u0026hellip;\n然后是结构化指令：\n## 任务 审查以下代码 ## 要求 1. 检查安全漏洞 2. 检查性能问题 3. 给出改进建议 ## 代码 ...\n再进阶是思维链（Chain-of-Thought）：\n让我们一步步思考\u0026hellip;\n还有 ReAct，让模型交替进行推理和行动：\nThought: 我需要先查看文件结构 Action: list_files Observation: \u0026hellip; Thought: 现在我需要\u0026hellip;\n如果把 LLM 比作一个程序，Prompt 就像是它的配置文件——定义了行为模式、输入格式、输出规范。好的配置让程序行为可预测、可控制。\nPrompt Engineering 的本质是什么？人工精心设计每一个 token，让有限的 context 窗口发挥最大价值。\n但局限也很明显：手动、静态、不可扩展。\n当知识库有一百万文档时，你不可能手动把相关内容塞进 prompt。\n3. 自动检索 Context — RAG # 有限的 context 窗口，无限的外部知识。怎么办？\nRAG（Retrieval-Augmented Generation）给出了答案：让相关信息自动找上门。用户提问 → 检索相关文档 → 拼入 Context → 生成回答。不再需要把所有知识塞进 prompt，只需要在需要时检索最相关的部分。\n这像什么？像是程序从文件系统读取数据，而不是把所有数据硬编码在代码里。\nContext 的稀缺性 # 这里要引入一个关键概念：Context Rot（上下文腐化）。\n随着 context 窗口中 token 数量增加，模型准确回忆信息的能力会下降。因为 Transformer 架构让每个 token 都要关注其他所有 token，形成 n² 的关系。当 n 变大，注意力被稀释。\n这意味着：Context 是稀缺资源，边际效用递减。不是塞得越多越好，而是要找到最小的高信号 token 集合。\nRAG 的局限 # RAG 本质上是一个固定模式的搜索工具：固定触发、固定流程、固定能力。\n它的突破在于：从\u0026quot;人工塞 Context\u0026quot;到\u0026quot;自动取 Context\u0026quot;。但它的局限也在于\u0026quot;固定\u0026quot;——如果 Agent 需要的不是检索，而是执行一段代码、调用一个 API 呢？\n4. 动态生成 Context — Tools # RAG 是工具的特例，Tools 是 RAG 的泛化。\nRAG：固定触发 → 检索 → 返回文本 Tools：Agent 决定 → 任意工具 → 返回结果\n这里先澄清一个概念：Workflow 是 LLM 和工具通过预定义路径编排，Agent 是 LLM 动态决定自己的流程。关键区别在于谁在做决策。\nTools 让 Agent 成为可能：不只检索还能执行，不只固定触发而是 Agent 自主决定，不只一个而是工具集。这像 Unix 中的可执行程序——cat 读文件，grep 搜索，sh 执行命令。简单、专注、c可组合。\n工具的输出拼入 Context，成为 Agent 的新感知。这是一个闭环：行动产生新的 Context，新的 Context 驱动下一步行动。Agent 第一次能\u0026quot;做事\u0026quot;并\u0026quot;看到结果\u0026quot;。\nMCP：工具的标准化 # 当 Agent 需要连接越来越多外部系统时，每个系统都需要单独的集成代码。MCP（Model Context Protocol） 解决了这个问题——它是 Agent 世界的 USB-C。\nMCP 提供统一协议，让 Agent 用同一种方式连接所有支持 MCP 的服务。它让 Tools 成为可发现、可组合的生态系统。\nMCP 的意义不只是减少重复工作。它让 Tools 成为可发现、可组合的生态系统。Agent 不需要预先知道所有工具，可以在运行时发现和使用新工具。\n5. 封装 Context 模式 — Skills # 有了工具，Agent 能做很多事。但问题也来了：\n工具太多，Context 不够用。 每个工具的定义、调用参数、返回结果都要占用 token。当 Agent 连接几十上百个工具时，光是工具定义就可能吃掉大量 context 窗口。\n而且原子工具太底层了。读文件、写文件、执行命令——这些是能力的原材料，不是能力本身。\n\u0026ldquo;代码审查\u0026quot;是一个能力。它需要：\n读取代码文件 理解项目结构 按照特定标准检查 输出结构化的审查意见 如何把这些组合成一个可复用的能力？\nSkill：可发现、可加载的 Context 包 # Skill 的本质是：一个包含指令、脚本和资源的文件夹，Agent 可以在需要时发现和加载。\n这个定义有三个关键点：\n文件夹结构：不是一段 prompt，而是有组织的资源集合 可发现：Agent 知道有哪些 Skill 可用 按需加载：只在相关时才加载到 Context Skill 的核心设计原则是 Progressive Disclosure（渐进式披露）：\n为什么这样设计？因为 Context 是稀缺资源。\n如果把所有 Skill 的完整内容都塞进 Context，会触发 Context Rot。渐进式披露让 Agent 只加载需要的信息，保持 Context 的高信噪比。\nSkill vs Shell 脚本 # Unix 哲学在这里再次闪光：用管道组合小程序，完成复杂任务。\ncat access.log | grep \u0026#34;ERROR\u0026#34; | sort | uniq -c | sort -rn | head -10 这行命令组合了 6 个小程序，完成了\u0026quot;找出最常见的 10 种错误\u0026quot;这个复杂任务。\nSkill 和 Shell 脚本有相似之处：\nTool → 单个命令（cat, grep, sort） Skill → Shell 脚本（组合多个命令的工作流） 但 Skill 比 Shell 脚本更灵活：\nShell 脚本是固定的流程 Skill 是指导 + 资源，Agent 可以灵活运用 Skill 还可以包含可执行代码。有些操作用代码比用 token 生成更高效、更可靠。比如排序一个列表，用代码是 O(n log n)，用 token 生成则昂贵且不确定。\n从 Context Engineering 的视角看，Skill 是可复用的 Context 模式——预定义好什么信息该进入 Context，以什么顺序，用什么方式处理。\n6. Context 的管理 — 长程任务的挑战 # 前面几章讲的是 Context 的来源：从哪里获取信息。\n但还有另一个维度：Context 的管理。当任务跨越几十分钟甚至几小时，产生的 token 远超 context 窗口时，怎么办？\nCompaction：压缩历史 # 最直接的方法是压缩。\n当对话接近 context 窗口上限时，让模型总结之前的内容，用摘要替换原始对话，然后继续。\n压缩的艺术在于选择保留什么。过于激进的压缩会丢失关键细节，过于保守则达不到效果。\n一个低风险的压缩策略是清理工具调用结果。当一个工具调用已经在历史深处，Agent 通常不需要再看原始返回值。\nStructured Note-taking：Agent 的笔记本 # 更优雅的方法是让 Agent 自己做笔记。\nAgent 定期把重要信息写入外部文件（比如 NOTES.md），这些笔记持久化在 context 窗口之外。需要时再读回来。\n这就像人类做笔记：我们不会记住所有细节，但会记录关键点，需要时查阅。\n一个有趣的例子是 Claude 玩 Pokémon。Agent 需要跨越数千个游戏步骤保持连贯性——记住目标、追踪进度、学习哪些攻击对哪些敌人有效。通过自己维护笔记，Agent 可以在 context 重置后继续多小时的策略执行。\nSub-agent：分而治之 # 第三种方法是多 Agent 协作。\n主 Agent 负责高层规划，子 Agent 负责具体执行。每个子 Agent 有自己干净的 context 窗口，可以深入探索，最后只返回精炼的结果。\n子 Agent 可能消耗数万 token 进行探索，但只返回 1000-2000 token 的精华。这实现了关注点分离——详细的搜索 context 隔离在子 Agent 内，主 Agent 专注于综合分析。\n选择哪种方法？ # Compaction：适合需要大量来回对话的任务 Note-taking：适合有明确里程碑的迭代开发 Sub-agent：适合需要并行探索的复杂研究 这三种方法可以组合使用。\n隔离环境：跨 Session 的外部记忆 # 当任务跨越数小时甚至数天时，每个新的 context window 都是一张白纸。想象轮班工程师交接，但每个人上班时都失去了前一班的记忆——这就是长程 Agent 的挑战。\n解决方案是隔离的运行环境：文件系统持久化代码和文档，Git 记录改动可回滚，进度文件记录工作日志。每个 session 结束时把环境留在\u0026quot;干净状态\u0026rdquo;，下一个 session 读取进度文件和 git log，几秒内就能继续工作。隔离环境是 Agent 的\u0026quot;外部记忆\u0026quot;，弥补了 context window 的有限性。\n关键是认识到：即使模型能力不断提升，在需要最强性能的场景下，Context 管理仍然是核心挑战。\n7. Context 的完整来源 — Environment # 现在让我们退后一步，看看全貌。\n前面的每一章，我们都在用操作系统做类比：\nContext 像程序的输入 Prompt 像配置文件 RAG 像文件系统读取 Tools 像可执行程序 Skills 像应用程序 这不是巧合。我们正在为 Agent 构建一个操作系统。\nEnvironment → 操作系统（完整运行环境） Agent → 用户/Shell（决策主体） Tools → 命令行程序（原子能力） Skills → 应用程序（封装的能力组合） Context → stdin/stdout（统一信息接口） 这让人想起 Unix 的设计哲学：Everything is a file。在 Unix 中，硬件、进程、网络连接都被抽象为文件，程序通过统一的文件接口与世界交互。\nUnix 的设计哲学在这里完美映射：\nEverything is a file → Everything is context 小程序做一件事 → Tool 做一件事 用管道组合程序 → 用 Skill 组合 Tools 文本作为通用接口 → Context 作为通用接口 Shell 作为胶水 → Agent 作为胶水 关键洞察：Agent 不直接接触 Environment，一切通过 Context 感知。\n就像 Unix 程序通过 stdin 读取输入、stdout 输出结果，Agent 通过 Context 感知世界、表达意图。\n为什么是 Coding Agent？ # 这里要回答一个更根本的问题：为什么我们如此强调 Coding Agent？\n因为我们相信：Agent 是通向 AGI 的可行路径。而 Coding Agent 是这条路径上最关键的形态。\n原因很简单：任何开放式任务，都可以转化为计算机操作。而代码执行是连接一切的桥梁。\n想想看：\n写一篇报告 → 操作文件系统 + 调用写作工具 分析数据 → 执行 Python 脚本 + 生成可视化 部署服务 → 执行命令行 + 配置环境 设计产品 → 调用设计工具 API + 生成原型 代码是通用的胶水。会写代码的 Agent，理论上可以完成任何可以用计算机完成的任务。\n换句话说：任何现在由人操作计算机完成的任务，未来都有可能由 Agent 自主完成。\n代码执行的独特价值 # 代码执行不只是\u0026quot;能做事\u0026quot;，它还解决了 Context Engineering 的核心挑战：\n1. 过滤数据，减少 token\n# 不用代码执行：10000 行数据全部进入 Context tool_call: get_spreadsheet(id=\u0026#34;abc123\u0026#34;) → 返回 10000 行，全部进入 Context # 用代码执行：在执行环境中过滤 data = get_spreadsheet(id=\u0026#34;abc123\u0026#34;) pending = [row for row in data if row[\u0026#34;status\u0026#34;] == \u0026#34;pending\u0026#34;] print(f\u0026#34;Found {len(pending)} pending orders\u0026#34;) print(pending[:5]) # 只返回 5 行到 Context 2. 保护隐私\n中间数据可以留在执行环境中，不进入模型的 Context。敏感信息（邮箱、电话）可以被自动脱敏。\n3. 持久化状态\nAgent 可以把中间结果写入文件，跨越 context 重置继续工作。甚至可以把成功的代码保存为可复用的函数——这就是 Skill 的雏形。\n这就是为什么 Environment 的核心是代码执行能力：\n对于 Coding Agent：\n代码文件的内容 → Context 终端的执行结果 → Context 测试的通过/失败 → Context 编译的错误信息 → Context LSP 的类型提示 → Context Environment 是 Context 的终极来源。Context 是 Agent 与世界的唯一接口。代码执行是 Agent 改变世界的主要方式。\n8. 结语：Context Engineering 的全貌 # 回顾这段旅程：\n每一步都在回答同一个问题：如何让 Agent 获得更好的 Context？\nPrompt Engineering：手工打磨每一个 token RAG：自动检索相关信息 Tools：动态执行获取新信息 Skills：封装可复用的 Context 模式 Environment：提供完整的信息来源 而 Context 管理（Compaction、Note-taking、Sub-agent）则回答另一个问题：如何在有限窗口里最大化 Context 的价值？\nContext Engineering = 来源 × 管理\n这一切，最终指向一个更大的图景：\n我们正在为 Agent 构建操作系统。\nUnix 用 50 年证明了一套设计哲学的生命力：\nEverything is a file 小程序做好一件事 用管道组合程序 文本作为通用接口 Agent 的世界正在复现这套哲学：\nEverything is context Tool 做好一件事 用 Skill 组合 Tools Context 作为通用接口 最后，回到开篇的问题：\nAgent 如何\u0026quot;看见\u0026quot;世界？\n答案始终是：Context。\nAgent 的能力上限 = Context 的质量上限\n这就是 Context Engineering。\n参考链接 # [1] Building Effective AI Agents: https://www.anthropic.com/engineering/building-effective-agents\n[2] Effective Context Engineering for AI Agents: https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents\n[3] What is Model Context Protocol (MCP)?: https://www.claude.com/blog/what-is-model-context-protocol\n[4] Code Execution with MCP: Building More Efficient Agents: https://www.anthropic.com/engineering/code-execution-with-mcp\n[5] Introducing Agent Skills: https://www.claude.com/blog/skills\n[6] Equipping Agents for the Real World with Agent Skills: https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills\n[7] Effective Harnesses for Long-Running Agents: https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents\n本文由 A\\ Opus 4.5 协作完成 ✨\n","date":"2025年12月6日","externalUrl":null,"permalink":"/posts/context-journey-blog/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e0. 引子\n    \u003cdiv id=\"0-引子\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#0-%e5%bc%95%e5%ad%90\" aria-label=\"\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003eAgent 如何\u0026quot;看见\u0026quot;世界？\u003c/p\u003e\n\u003cp\u003e它没有眼睛，没有耳朵，只有一个输入窗口。无论外面的世界多复杂，Agent 能感知的只有一样东西：\u003cstrong\u003eContext\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e一段 prompt 是 context，一次工具调用的返回是 context，一个文件的内容是 context，一条报错信息也是 context。\u003c/p\u003e\n\u003cp\u003e对于 Agent 来说：\u003cstrong\u003eEverything is context\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e这篇文章讲述 context 如何从一段静态文字，演进为 Agent 感知世界的唯一接口。这个演进过程，就是 \u003cstrong\u003eContext Engineering\u003c/strong\u003e 的诞生之路。\u003c/p\u003e\n\u003chr\u003e\n\n\u003ch2 class=\"relative group\"\u003e1. Context 的起源 — In-Context Learning\n    \u003cdiv id=\"1-context-的起源--in-context-learning\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#1-context-%e7%9a%84%e8%b5%b7%e6%ba%90--in-context-learning\" aria-label=\"\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003e传统机器学习的范式很简单：一个任务，训练一个模型。\u003c/p\u003e\n\u003cp\u003e情感分析是一个模型，机器翻译是另一个模型。能力固化在参数里，换任务就要重新训练。\u003c/p\u003e\n\u003cp\u003eLLM 打破了这个范式。GPT 系列证明了一件事：一个足够大的语言模型，可以通过 \u003cstrong\u003econtext\u003c/strong\u003e 来切换任务。你不需要重新训练，只需要换一段 prompt。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e传统模型\u003c/strong\u003e：任务 → 训练 → 专用模型\u003c/p\u003e","title":"从 Prompt 到 Environment：Context 的进化之旅 —— 理解 Agent 应用的核心演进","type":"posts"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]